{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import packages"
      ],
      "metadata": {
        "id": "EOGdgMFyeyIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXFDbsk0eust",
        "outputId": "41c1227c-2bfe-4923-a568-aa1f17fb3fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install loralib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "6xpOEs-0e8wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Loader"
      ],
      "metadata": {
        "id": "VXc5irgyfMiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCAOsP0rfPFS",
        "outputId": "ec6705e7-42a2-436b-c3eb-bfd6a99c0162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29731767.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LoRA"
      ],
      "metadata": {
        "id": "eGwwkN1efnHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRA_layer():\n",
        "  def __init__ (\n",
        "      self,\n",
        "      r: int,\n",
        "      lora_alpha: int,\n",
        "      lora_dropout: float,\n",
        "      merge_weights: bool,\n",
        "  ):\n",
        "    self.r = r\n",
        "    self.lora_alpha = lora_alpha\n",
        "    if lora_dropout > 0.:\n",
        "      self.lora_dropout = nn.Dropout(p=lora_dropout)\n",
        "    else:\n",
        "      self.lora_dropout = lambda x: x\n",
        "    self.merged = False\n",
        "    self.merge_weights = merge_weights"
      ],
      "metadata": {
        "id": "oowZmX-vflvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRA_Linear(nn.Linear, LoRA_layer):\n",
        "  def __init__ (\n",
        "      self,\n",
        "      in_features: int,\n",
        "      out_features: int,\n",
        "      r: int = 0,\n",
        "      lora_alpha: int = 1,\n",
        "      lora_dropout: float = 0.,\n",
        "      merge_weights: bool = True,\n",
        "      **kwargs\n",
        "  ):\n",
        "    nn.Linear.__init__(self, in_features, out_features, **kwargs)\n",
        "    LoRA_layer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, merge_weights=merge_weights)\n",
        "\n",
        "    if r > 0:\n",
        "      self.lora_A = nn.Parameter(self.weight.new_zeros((r, in_features)))\n",
        "      self.lora_B = nn.Parameter(self.weight.new_zeros((out_features, r)))\n",
        "      self.scaling = self.lora_alpha / self.r\n",
        "      self.weight.requires_grad = False\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.Linear.reset_parameters(self)\n",
        "    if hasattr(self, 'lora_A'):\n",
        "      nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "      nn.init.zeros_(self.lora_B)\n",
        "\n",
        "  def train(self, mode: bool = True):\n",
        "    nn.Linear.train(self, mode)\n",
        "\n",
        "    # Training mode\n",
        "    if mode:\n",
        "      if self.merge_weights and self.merged:\n",
        "        if self.r > 0:\n",
        "          self.weight.data -= (self.lora_B @ self.lora_A) * self.scaling\n",
        "        self.merged = False\n",
        "\n",
        "    # Evaluation mode\n",
        "    else:\n",
        "      if self.merge_weights and not self.merged:\n",
        "        if self.r > 0:\n",
        "          self.weight.data += (self.lora_B @ self.lora_A) * self.scaling\n",
        "        self.merged = True\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    # Evaluation mode\n",
        "    if self.r > 0 and not self.merged:\n",
        "      result = F.linear(x, self.weight, bias=self.bias)\n",
        "      result += (self.lora_dropout(x) @ self.lora_A.transpose(0, 1)) @ self.lora_B.transpose(0, 1) * self.scaling\n",
        "      return result\n",
        "    else:\n",
        "       return F.linear(x, self.weight, bias=self.bias)\n"
      ],
      "metadata": {
        "id": "-3a3GEd-ghIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Modeling"
      ],
      "metadata": {
        "id": "bJPc25Tjkewj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainable_params(model):\n",
        "  total_params = 0\n",
        "  for param in model.parameters():\n",
        "    if param.requires_grad:\n",
        "      total_params += param.numel()\n",
        "\n",
        "  print(f\"Trainable params: {total_params/1e6:.2f} M\")"
      ],
      "metadata": {
        "id": "ymuiwLelhf7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Load pre-trained VGG16 ImageNet1k"
      ],
      "metadata": {
        "id": "lzIIvRiek7zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "vgg16_model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "vgg16_classifier_ckpt = vgg16_model.classifier.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcnnR9BSk5ZQ",
        "outputId": "dfcc7ea6-0901-4910-acf0-de615add48e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 107MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(vgg16_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIS18dC6lYb3",
        "outputId": "f118726c-a969-41dc-dec4-6811ba9f1fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 138.36 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Define classifier with LoRA"
      ],
      "metadata": {
        "id": "M27NUtNMlpkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_classifier = nn.Sequential(\n",
        "    LoRA_Linear(\n",
        "        in_features=512*7*7,\n",
        "        out_features=4096,\n",
        "        bias=True,\n",
        "        r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(\n",
        "        in_features=4096,\n",
        "        out_features=4096,\n",
        "        bias=True,\n",
        "        r=16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(\n",
        "        in_features=4096,\n",
        "        out_features=1000,\n",
        "        bias=True,\n",
        "        r=16),\n",
        ")"
      ],
      "metadata": {
        "id": "5hY5P2vOlcEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Load pre-trained weights into LoRA classifier"
      ],
      "metadata": {
        "id": "RGzWWXF6mR7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_classifier.load_state_dict(vgg16_classifier_ckpt, strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jrv5fxWmOkP",
        "outputId": "62cbec8f-8665-48da-99d3-1d3aa8a81f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['0.lora_A', '0.lora_B', '3.lora_A', '3.lora_B', '6.lora_A', '6.lora_B'], unexpected_keys=[])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. Add a layer with 10 output feature for CIFAR10 dataset classification"
      ],
      "metadata": {
        "id": "sqRbQmC1nJvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_classifier = nn.Sequential(\n",
        "    *lora_classifier,\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    LoRA_Linear(in_features=1000, out_features=10, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "Fv1cCEHtmbXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params(new_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h94a5nh5ntNG",
        "outputId": "59ab5cd8-f206-4cf5-e6bc-82faf70c62fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0.70 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5. Wrap pre-trained VGG16 features with LoRA classifier"
      ],
      "metadata": {
        "id": "o1M_f2AEn5uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLS_model(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.features = vgg16_model.features.eval()\n",
        "    for param in self.features.parameters():\n",
        "      param.requires_grad = False\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "    self.classifier = new_classifier\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "XrRu1TyjnuOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLS_model().to(device)"
      ],
      "metadata": {
        "id": "iG3ubow5otZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Training"
      ],
      "metadata": {
        "id": "8UU6N2-No3na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "e9jz0dOkoy6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(10):\n",
        "  running_loss = 0.0\n",
        "  for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{10}], Average Loss: {running_loss / len(trainloader): .4f}, GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB, GPU Memory Reserved: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB\")\n",
        "\n",
        "\n",
        "print(f\"Training time: {time.time() - start:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNNt9izlo_XX",
        "outputId": "35faa848-dd28-4d48-916e-f175c6061fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Average Loss:  1.5352, GPU Memory Allocated: 561.50 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [2/10], Average Loss:  1.2858, GPU Memory Allocated: 561.50 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [3/10], Average Loss:  1.2096, GPU Memory Allocated: 558.74 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [4/10], Average Loss:  1.1554, GPU Memory Allocated: 558.49 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [5/10], Average Loss:  1.1154, GPU Memory Allocated: 558.75 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [6/10], Average Loss:  1.0886, GPU Memory Allocated: 561.50 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [7/10], Average Loss:  1.0636, GPU Memory Allocated: 561.50 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [8/10], Average Loss:  1.0433, GPU Memory Allocated: 558.74 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [9/10], Average Loss:  1.0229, GPU Memory Allocated: 558.49 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Epoch [10/10], Average Loss:  1.0019, GPU Memory Allocated: 561.50 MB, GPU Memory Reserved: 1272.00 MB\n",
            "Training time: 164.52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluate"
      ],
      "metadata": {
        "id": "uScEOmFUqd88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in testloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on 10000 test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM1L9LRpqZhn",
        "outputId": "7c7b33f4-6c07-40b4-eb96-5504500ef26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on 10000 test images: 64.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g256FTzyq8WK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}